# Task 4.1: Velocity Detection

## Goal

Detect high-velocity scraping patterns.

## Context

Scraping patterns to detect:
- Sequential access (100 requests/60s)
- Bulk access (50 unique/60s)
- High-frequency access

See `../CONVEX_GUIDE.md` for Convex best practices (indexes, validators, helpers).

## PRD
```json
{
  "category": "functional",
  "description": "Velocity-based scraping detection",
  "steps": [
    "Create scraping detection helpers",
    "Add velocity check to rate limit",
    "Log scraping alerts",
    "Add tests"
  ],
  "passes": false
}
```

## Success

- [ ] Velocity helpers created
- [ ] Detection implemented
- [ ] Alerts logged
- [ ] Tests pass

## Commands

```bash
pnpm lint
pnpm typecheck
pnpm test
```

## Subtasks

### Subtask 4.1.1: Create Velocity Helpers

**File**: `packages/backend/convex/model/scrapingDetection.ts`

**Implementation**:

```typescript
export interface ScrapingAlert {
  alertType: "sequential_access" | "bulk_access" | "velocity_exceeded";
  severity: "critical" | "warning";
  details: string;
}

export interface VelocityMetrics {
  requestsInLastMinute: number;
  requestsInLastHour: number;
  uniquePathsInLastMinute: number;
  uniquePathsInLastHour: number;
}

export async function checkVelocity(
  apiKeyId: string,
  accessLogs: Array<{ accessedAt: number; contentSlug: string }>
): Promise<ScrapingAlert | null> {
  const now = Date.now();
  const oneMinuteAgo = now - 60000;
  const oneHourAgo = now - 3600000;

  const recentLogs = accessLogs.filter((log) => log.accessedAt >= oneHourAgo);

  const requestsInLastMinute = recentLogs.filter((log) => log.accessedAt >= oneMinuteAgo).length;
  const requestsInLastHour = recentLogs.length;

  const uniquePathsInLastMinute = new Set(
    recentLogs.filter((log) => log.accessedAt >= oneMinuteAgo).map((log) => log.contentSlug)
  ).size;

  const uniquePathsInLastHour = new Set(recentLogs.map((log) => log.contentSlug)).size;

  if (requestsInLastMinute > 100) {
    return {
      alertType: "velocity_exceeded",
      severity: "critical",
      details: `${requestsInLastMinute} requests in last minute (limit: 100)`,
    };
  }

  if (uniquePathsInLastMinute > 50) {
    return {
      alertType: "bulk_access",
      severity: "critical",
      details: `${uniquePathsInLastMinute} unique paths in last minute (limit: 50)`,
    };
  }

  return null;
}
```


**Output**: Velocity helpers

---

### Subtask 4.1.2: Integrate with Rate Limit

**File**: `packages/backend/convex/model/rateLimit.ts`

**Changes**:

```typescript
import { checkVelocity, type ScrapingAlert } from "./scrapingDetection";

export async function checkRateLimitWithScraping(
  ctx: any,
  args: RateLimitCheckArgs
): Promise<RateLimitCheckResult> {
  const rateLimitResult = await checkRateLimitHelper(ctx, args);

  if (!rateLimitResult.allowed) {
    return rateLimitResult;
  }

  const accessLogs = await ctx.db
    .query("contentAccessLog")
    .withIndex("apiKeyId_accessedAt")
    .eq("apiKeyId", args.apiKeyId)
    .gt("accessedAt", Date.now() - 3600000)
    .take(1000)
    .collect();

  const scrapingAlert = await checkVelocity(args.apiKeyId, accessLogs);

  if (scrapingAlert) {
    await ctx.db.insert("scrapingAlerts", {
      apiKeyId: args.apiKeyId,
      alertType: scrapingAlert.alertType,
      severity: scrapingAlert.severity,
      details: scrapingAlert.details,
      createdAt: Date.now(),
      resolved: false,
    });

    if (scrapingAlert.severity === "critical") {
      return {
        allowed: false,
        retryAfter: 86400,
        remaining: 0,
      };
    }
  }

  return rateLimitResult;
}
```

**Output**: Velocity detection integrated

---

### Subtask 4.1.3: Add Tests

**File**: `packages/backend/convex/model/__tests__/scrapingDetection.test.ts`

**Tests**:

```typescript
describe("checkVelocity", () => {
  it("should detect velocity exceeded", async () => {
    const logs = createMockLogs(150, "1 minute");

    const alert = await checkVelocity(testApiKeyId, logs);

    expect(alert?.alertType).toBe("velocity_exceeded");
    expect(alert?.severity).toBe("critical");
  });

  it("should detect bulk access", async () => {
    const logs = createMockLogs(60, "1 minute", true);

    const alert = await checkVelocity(testApiKeyId, logs);

    expect(alert?.alertType).toBe("bulk_access");
  });

  it("should not alert on normal usage", async () => {
    const logs = createMockLogs(20, "1 hour");

    const alert = await checkVelocity(testApiKeyId, logs);

    expect(alert).toBeNull();
  });
});
```

**Output**: Tests

---

## Next Steps

After: Task 4.2 - IP-Based Limiting

## Related

- Task 4.2: IP Rate Limiting (complementary to this)
- Task 4.3: Request Signatures (adds evidence)
- Task 4.5: Auto-Revocation (triggers on critical alerts)

## Progress

```
[YYYY-MM-DD HH:mm] Task 4.1 completed

Key decisions:
- Use in-memory filtering for velocity checks
- Separate scrapingAlerts table for tracking
- Critical alerts trigger immediate blocking

Files changed:
- packages/backend/convex/model/scrapingDetection.ts
- packages/backend/convex/model/rateLimit.ts
- packages/backend/convex/model/__tests__/scrapingDetection.test.ts

Blockers: None
```
