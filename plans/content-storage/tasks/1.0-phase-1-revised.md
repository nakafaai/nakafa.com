# Phase 1: Content Sync to Convex

## Core Insight

**We store raw MDX body content, NOT the metadata export.**

The MDX file contains:
1. `export const metadata = {...}` - **Extracted as structured fields, NOT stored in body**
2. MDX body content - **Stored as raw text in `body` field**

The `export const metadata` is for Next.js bundling only. In Convex, we store:
- Metadata fields separately (title, description, authors, date)
- Body content without the metadata export

## What We Store in Convex

| Field | Source | Stored As |
|-------|--------|-----------|
| `locale` | File path | `"en"` or `"id"` |
| `slug` | File path | `"articles/politics/my-article"` |
| `title` | Extracted from metadata | `"My Article Title"` |
| `description` | Extracted from metadata | `"Article description..."` |
| `date` | Extracted from metadata | `1706140800000` (epoch ms) |
| `body` | **File content MINUS metadata export** | Raw MDX text starting with `## Abstract...` |
| `contentHash` | SHA-256 of body | For change detection |
| `authors` | Extracted from metadata | Linked via `contentAuthors` join table |

## Verified Implementation

```typescript
// packages/backend/scripts/lib/mdxParser.ts

const METADATA_REGEX = /export\s+const\s+metadata\s*=\s*({[\s\S]*?});/;

export function parseMdxContent(content: string): ParsedMdx {
  // 1. Extract metadata object via regex
  const match = content.match(METADATA_REGEX);
  const metadataObject = new Function(`return ${match[1]}`)();
  
  // 2. Validate with Zod schema
  const metadata = ContentMetadataSchema.parse(metadataObject);
  
  // 3. Remove metadata export from body - CRITICAL!
  const body = content.replace(METADATA_REGEX, "").trim();
  
  return { metadata, body, contentHash: computeHash(body) };
}
```

**Tested output:**
- `metadata` = `{ title: "...", description: "...", authors: [...], date: "..." }`
- `body` = `"## Abstract\n\nThe legitimacy of..."` (no `export const metadata`)

## Architecture

```
┌─────────────────────────────────────────────────────────────────────┐
│                         Sync Flow                                    │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  1. CLI Script (tsx)                                                │
│     ├── glob MDX files                                              │
│     ├── Read file as text                                           │
│     ├── Extract metadata (regex + new Function)                     │
│     ├── Strip metadata export from body                             │
│     ├── Validate with Zod (ContentMetadataSchema)                   │
│     └── Call `npx convex run` with batched data                     │
│                                                                      │
│  2. Convex Internal Action                                          │
│     ├── Receive batch of { metadata, body, ... }                    │
│     ├── Upsert content (check hash for changes)                     │
│     └── Sync authors via contentAuthors join table                  │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

## Tasks

| Task | Status | Description |
|------|--------|-------------|
| 1.1 | DONE | Create mdxParser.ts utilities |
| 1.2 | DONE | Create sync mutations (upsert, author linking) |
| 1.3 | DONE | Simplify mdxParser to use Zod schemas |
| 1.4 | DONE | Add @repo/contents dependency |
| 1.5a | PENDING | Live sync articles (14 files) |
| 1.5b | PENDING | Live sync subjects (606 files) |
| 1.5c | PENDING | Live sync exercises (920 files) |

## Content Counts

File counts are discovered via glob patterns during dry-run:

```bash
pnpm --filter backend sync:articles --dry-run
# Output: "Found 14 article files"

pnpm --filter backend sync:subjects --dry-run  
# Output: "Found 606 subject files"

pnpm --filter backend sync:exercises --dry-run
# Output: "Found 920 exercise files"
```

| Type | Glob Pattern | Files | Unique Content |
|------|--------------|-------|----------------|
| Articles | `articles/**/*.mdx` | 14 | 7 articles x 2 locales |
| Subjects | `subject/**/*.mdx` | 606 | 303 subjects x 2 locales |
| Exercises | `exercises/**/_question/*.mdx` | 920 | 460 exercises x 2 locales |

## Commands

```bash
# Dry run (no database changes, shows file counts)
pnpm --filter backend sync:articles --dry-run
pnpm --filter backend sync:subjects --dry-run
pnpm --filter backend sync:exercises --dry-run

# Live sync (requires Convex dev server running)
pnpm --filter backend dev                    # Terminal 1
pnpm --filter backend sync:articles          # Terminal 2
pnpm --filter backend sync:subjects
pnpm --filter backend sync:exercises
```

## Success Criteria

- [x] Body content does NOT contain `export const metadata`
- [x] Metadata extracted as structured fields
- [x] Zod validation with existing schemas
- [x] Dry-run tests pass
- [ ] Live sync completes for all content types
- [ ] Re-run shows "unchanged" for all content
- [ ] Data viewable in Convex dashboard

---

**Last Updated**: January 24, 2026
**Status**: Ready for live sync
