# Task 1.1: Create Script Generation Action

## ðŸŽ¯ Goal

Create an action that uses AI to convert educational content into a podcast-style script with intonation markers.

## ðŸ“ Context

The script generation transforms dry educational content into engaging, natural-sounding narration. It adds ElevenLabs v3 audio tags like [excited], [sigh], [pauses] that help ElevenLabs produce better speech.

## PRD

```json
{
  "category": "integration",
  "description": "Create AI action to generate podcast-style scripts from article/subject content",
  "steps": [
    "Create script generation action",
    "Fetch content from articleContents or subjectSections",
    "Use Gemini via Vercel AI Gateway for script generation",
    "Add ElevenLabs v3 audio tags for emotional context",
    "Update contentAudios with generated script",
    "Handle errors gracefully using ConvexError"
  ],
  "passes": false
}
```

## ðŸŽ¬ Success Criteria

- [ ] Action exists at `packages/backend/convex/audioStudies/actions.ts`
- [ ] Uses generateText from AI SDK
- [ ] Fetches content dynamically based on contentId + contentType
- [ ] Generates script with ElevenLabs v3 audio tags
- [ ] Updates contentAudios status and script fields
- [ ] Handles errors with ConvexError

## Commands

```bash
pnpm typecheck
pnpm lint
```

## ðŸ“ Subtasks

### Subtask 1.1.1: Create Script Generation Action

**File to create**: `packages/backend/convex/audioStudies/actions.ts`

**Implementation**:

```typescript
import { action, internalAction } from "@repo/backend/convex/functions";
import { internal } from "./_generated/api";
import { generateText } from "ai";
import { vercelGateway } from "@repo/ai/config/vercel";
import { vv } from "@repo/backend/convex/lib/validators";
import { v, ConvexError } from "convex/values";
import type { Id } from "./_generated/dataModel";

/**
 * Generate podcast script from content using AI.
 * Called by workflow to transform educational content into natural narration.
 */
export const generateScript = internalAction({
  args: {
    contentAudioId: vv.id("contentAudios"),
  },
  returns: v.null(),
  handler: async (ctx, args) => {
    // Fetch the audio study record
    const audioStudy = await ctx.runQuery(
      internal.audioStudies.queries.getContentAudio,
      { contentAudioId: args.contentAudioId }
    );

    if (!audioStudy) {
      throw new ConvexError({
        code: "NOT_FOUND",
        message: "Audio study not found",
      });
    }

    // Update status to generating_script
    await ctx.runMutation(
      internal.audioStudies.mutations.updateStatus,
      {
        contentAudioId: args.contentAudioId,
        status: "generating_script",
      }
    );

    try {
      // Fetch content based on type
      const content = await fetchContent(ctx, {
        contentId: audioStudy.contentId,
        contentType: audioStudy.contentType,
      });

      // Generate script using AI
      const { text: script } = await generateText({
        model: vercelGateway.languageModel("google/gemini-2.5-flash"),
        system: `You are an expert educational podcast script writer.

Transform educational content into an engaging, natural-sounding podcast script.

Guidelines:
- Write in a conversational but informative tone
- Use clear, accessible language while maintaining academic accuracy
- Include an intro hook and outro summary
- Add ElevenLabs v3 audio tags to guide the narrator:
  [excited] - For enthusiasm, discoveries, key points
  [curious] - For questions, mysteries, thought-provoking content
  [calm] - For complex explanations, background info
  [pauses] - Brief pause for comprehension
  [sigh] - Longer pause between major sections
  [laughs] - Light humor or friendly moment
  [whispers] - Intimate or secretive moment
  [cheerfully] - Happy, upbeat tone
  [flatly] - Neutral, factual delivery
  [hesitates] - Uncertainty or thinking
  [nervously] - Anxious or unsure
  [sorrowful] - Sad or serious moment

Example:
"[excited] Today we're exploring something fascinating! [pauses] Did you know that [curious] every number has a unique story? Let's discover why..."`,
        prompt: createScriptPrompt({ ...content, locale: audioStudy.locale }),
      });

      // Save the script
      await ctx.runMutation(
        internal.audioStudies.mutations.saveScript,
        {
          contentAudioId: args.contentAudioId,
          script,
        }
      );
    } catch (error) {
      // Update status to failed
      await ctx.runMutation(
        internal.audioStudies.mutations.markFailed,
        {
          contentAudioId: args.contentAudioId,
          errorMessage: error instanceof Error ? error.message : "Script generation failed",
        }
      );
      throw error;
    }

    return null;
  },
});

/**
 * Helper to fetch content from either articles or subject sections
 */
async function fetchContent(
  ctx: ActionCtx,
  args: {
    contentId: string;
    contentType: "article" | "subject";
  }
) {
  if (args.contentType === "article") {
    const article = await ctx.runQuery(
      internal.audioStudies.queries.getArticleContent,
      { articleId: args.contentId as Id<"articleContents"> }
    );
    if (!article) {
      throw new ConvexError({
        code: "NOT_FOUND",
        message: "Article not found",
      });
    }
    return {
      title: article.title,
      description: article.description,
      body: article.body,
      locale: article.locale,
    };
  } else {
    const section = await ctx.runQuery(
      internal.audioStudies.queries.getSubjectSection,
      { sectionId: args.contentId as Id<"subjectSections"> }
    );
    if (!section) {
      throw new ConvexError({
        code: "NOT_FOUND",
        message: "Subject section not found",
      });
    }
    return {
      title: section.title,
      description: section.description,
      body: section.body,
      locale: section.locale,
    };
  }
}

/**
 * Create prompt for script generation
 */
function createScriptPrompt(content: {
  title: string;
  description?: string;
  body: string;
  locale: "en" | "id";
}): string {
  const language = content.locale === "id" ? "Indonesian" : "English";
  
  return `Create a podcast script in ${language} for the following educational content.

TITLE: ${content.title}

${content.description ? `DESCRIPTION: ${content.description}\n\n` : ""}
CONTENT:
${content.body}

Transform this into a 3-5 minute educational podcast script in ${language}. Include ElevenLabs v3 audio tags as specified in your instructions.`;
}
```

**Output**: Script generation action with proper ElevenLabs v3 audio tags and ConvexError handling.

---

## ðŸš€ Next Steps

After this task:
- Next: Task 1.2 (Create speech generation action)
- Dependencies: Task 0.2 (schema), Task 0.1 (voice config for voice settings)

## ðŸ”— Related Tasks

- Task 1.3: Workflow calls this action
- Task 2.1: Queries used by this action

## âš ï¸ Important Notes

### ElevenLabs v3 Audio Tags Format

**Correct format** (ElevenLabs v3):
- `[excited]`, `[curious]`, `[calm]` - Emotional states
- `[pauses]`, `[sigh]` - Pauses and breathing
- `[laughs]`, `[whispers]` - Vocal reactions
- `[cheerfully]`, `[flatly]` - Tone modifiers
- `[hesitates]`, `[nervously]` - Cognitive beats

**Wrong format** (do NOT use):
- âŒ `[EMOTION: excited]`
- âŒ `[PAUSE]`
- âŒ `[EMPHASIS]`
- âŒ `[SLOW]`

### Model Selection

Using `google/gemini-2.5-flash` via Vercel AI Gateway because:
- Fast generation for real-time workflows
- Good quality for educational content
- Cost-effective for script generation

Alternative: `anthropic/claude-sonnet-4-5` for higher quality if needed.

### Error Handling

Always use `ConvexError` for user-facing errors:
- NOT_FOUND: Resource doesn't exist
- BAD_REQUEST: Invalid state or parameters

Update status to "failed" on errors so:
1. Users see clear error state
2. We can retry with backoff
3. generationAttempts counter tracks retries

### Content Size Limits

If content is very long (>8000 tokens):
1. Truncate body with "..." indicator
2. Or split into multiple audio segments (future enhancement)
3. For now, assume content fits in context window

### Script Length

Target 3-5 minutes of audio:
- ~450-750 words for normal pace
- Script generation prompt requests this length
- ElevenLabs will respect pacing from audio tags
