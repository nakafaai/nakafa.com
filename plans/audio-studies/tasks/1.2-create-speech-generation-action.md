# Task 1.2: Create Speech Generation Action

## üéØ Goal

Create an action that converts the generated script into audio using ElevenLabs via AI SDK.

## üìç Context

This action takes the script with intonation markers and generates speech using ElevenLabs. It stores the resulting audio in Convex storage and updates the contentAudios record.

## PRD

```json
{
  "category": "integration",
  "description": "Create action to convert script to speech using ElevenLabs AI SDK",
  "steps": [
    "Create speech generation action",
    "Fetch script and voice settings from contentAudios",
    "Use ElevenLabs via AI SDK for TTS",
    "Store audio blob in Convex storage",
    "Get audio metadata (duration, size)",
    "Update contentAudios with storage reference",
    "Handle errors with proper cleanup"
  ],
  "passes": false
}
```

## üé¨ Success Criteria

- [ ] Action exists in `packages/backend/convex/audioStudies/actions.ts`
- [ ] Uses experimental_generateSpeech from AI SDK
- [ ] ElevenLabs configured via @ai-sdk/elevenlabs
- [ ] Audio stored in Convex storage
- [ ] Audio metadata (duration, size) captured
- [ ] Updates contentAudios with audioStorageId
- [ ] Handles errors gracefully

## Commands

```bash
pnpm typecheck
pnpm lint
```

## üìù Subtasks

### Subtask 1.2.1: Create Speech Generation Action

**File to modify**: `packages/backend/convex/audioStudies/actions.ts` (add to existing file)

**Implementation**:

```typescript
import { experimental_generateSpeech as generateSpeech } from "ai";
import { elevenlabs } from "@repo/ai/config/elevenlabs";
import { ConvexError } from "convex/values";

/**
 * Generate speech from script using ElevenLabs.
 * Called by workflow after script generation.
 */
export const generateSpeechAction = internalAction({
  args: {
    contentAudioId: vv.id("contentAudios"),
  },
  returns: v.null(),
  handler: async (ctx, args) => {
    // Fetch the audio study with script
    const audioStudy = await ctx.runQuery(
      internal.audioStudies.queries.getContentAudioWithScript,
      { contentAudioId: args.contentAudioId }
    );

    if (!audioStudy) {
      throw new ConvexError({
        code: "NOT_FOUND",
        message: "Audio study not found",
      });
    }

    if (!audioStudy.script) {
      throw new ConvexError({
        code: "BAD_REQUEST",
        message: "Audio study has no script",
      });
    }

    // Update status to generating_speech
    await ctx.runMutation(
      internal.audioStudies.mutations.updateStatus,
      {
        contentAudioId: args.contentAudioId,
        status: "generating_speech",
      }
    );

    try {
      // Generate speech using ElevenLabs via AI SDK
      const result = await generateSpeech({
        model: elevenlabs.speech("eleven_multilingual_v2"),
        text: audioStudy.script,
        voice: audioStudy.voiceId,
        providerOptions: {
          elevenlabs: {
            voiceSettings: audioStudy.voiceSettings || {
              stability: 0.5,
              similarityBoost: 0.75,
            },
          },
        },
      });

      // Store audio in Convex storage
      const storageId = await ctx.storage.store(result.audio);

      // Calculate audio metadata
      const audioSize = result.audio.byteLength || result.audio.length;
      
      // Estimate duration (rough approximation: 150 words per minute)
      const wordCount = audioStudy.script.split(/\s+/).length;
      const estimatedDuration = Math.ceil((wordCount / 150) * 60); // seconds

      // Save storage reference and metadata
      await ctx.runMutation(
        internal.audioStudies.mutations.saveAudio,
        {
          contentAudioId: args.contentAudioId,
          storageId,
          audioDuration: estimatedDuration,
          audioSize,
        }
      );
    } catch (error) {
      // Clean up any partial storage if needed
      await ctx.runMutation(
        internal.audioStudies.mutations.markFailed,
        {
          contentAudioId: args.contentAudioId,
          errorMessage: error instanceof Error ? error.message : "Speech generation failed",
        }
      );
      throw error;
    }

    return null;
  },
});
```

**Output**: Speech generation action integrated with ElevenLabs.

### Subtask 1.2.2: Verify ElevenLabs Configuration

**File to verify**: `packages/ai/config/elevenlabs.ts`

**Should already be** (from previous task):

```typescript
import { createElevenLabs } from "@ai-sdk/elevenlabs";
import { keys } from "@repo/ai/keys";

export const elevenlabs = createElevenLabs({
  apiKey: keys().ELEVENLABS_API_KEY,
});
```

**Output**: ElevenLabs provider configured for AI SDK.

---

## üöÄ Next Steps

After this task:
- Next: Task 1.3 (Create workflow orchestrator)
- Dependencies: Task 1.1 (script generation)

## üîó Related Tasks

- Task 1.3: Workflow calls this action
- Task 2.2: Mutations used by this action

## ‚ö†Ô∏è Important Notes

### Audio Duration Estimation

We're estimating duration because:
1. ElevenLabs API doesn't always return exact duration
2. 150 words/minute is standard speaking pace
3. Intonation markers may affect actual duration slightly

For more accuracy, we could:
- Parse audio file headers (complex in actions)
- Store estimated and update when played (overkill)
- Accept ~10% variance in estimates

### Storage Format

`result.audio` from AI SDK is a `Uint8Array` or `ArrayBuffer`. `ctx.storage.store()` accepts `Blob | ArrayBuffer | Uint8Array`, so we pass it directly.

### Error Cleanup

If speech generation fails after creating storage:
1. Storage orphaned (acceptable, minimal cost)
2. Or implement cleanup by storing storageId temporarily and deleting on error

For simplicity, we don't clean up on error. Orphaned files can be cleaned via periodic job later.

### Model Selection

Using `eleven_multilingual_v2` because:
- Supports Indonesian and English (our locales)
- High quality for educational content
- Good handling of intonation markers

Alternative: `eleven_flash_v2_5` for faster generation (slightly lower quality).
